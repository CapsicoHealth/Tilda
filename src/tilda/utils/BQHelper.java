/* ===========================================================================
 * Copyright (C) 2020 CapsicoHealth Inc.
 * ===========================================================================
 */
package tilda.utils;

import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.util.ArrayList;
import java.util.List;

import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;

import com.google.api.gax.paging.Page;
import com.google.auth.oauth2.ServiceAccountCredentials;
import com.google.cloud.bigquery.BigQuery;
import com.google.cloud.bigquery.BigQuery.DatasetListOption;
import com.google.cloud.bigquery.BigQuery.TableListOption;
import com.google.cloud.bigquery.BigQueryError;
import com.google.cloud.bigquery.BigQueryException;
import com.google.cloud.bigquery.BigQueryOptions;
import com.google.cloud.bigquery.Dataset;
import com.google.cloud.bigquery.DatasetInfo;
import com.google.cloud.bigquery.Field;
import com.google.cloud.bigquery.FieldValueList;
import com.google.cloud.bigquery.FormatOptions;
import com.google.cloud.bigquery.Job;
import com.google.cloud.bigquery.JobId;
import com.google.cloud.bigquery.JobInfo;
import com.google.cloud.bigquery.JobInfo.WriteDisposition;
import com.google.cloud.bigquery.QueryJobConfiguration;
import com.google.cloud.bigquery.Schema;
import com.google.cloud.bigquery.StandardSQLTypeName;
import com.google.cloud.bigquery.Table;
import com.google.cloud.bigquery.TableDataWriteChannel;
import com.google.cloud.bigquery.TableId;
import com.google.cloud.bigquery.TableResult;
import com.google.cloud.bigquery.WriteChannelConfiguration;

import tilda.db.TildaMasterRuntimeMetaData;
import tilda.db.TildaObjectMetaData;
import tilda.types.ColumnDefinition;

public class BQHelper
  {
    protected static final Logger LOG                   = LogManager.getLogger(BQHelper.class.getName());

    protected static final String _DEFAULT_ENV_VAR_NAME = "GCP_SERVICE_ACCOUNT_CREDENTIALS_PATH";

    /**
     * Given the environment variable 'GCP_SERVICE_ACCOUNT_CREDENTIALS_PATH', looks up the value which points to a path, and then
     * based on the project name, lookup the file "<GCP_SERVICE_ACCOUNT_CREDENTIALS_PATH>/<dataProjectName>.xxx.key.bq.json".
     * 'xxx' can be anything (and is optional) but is generally the first few characters of the original key file. This is done
     * so different keys to the same project could be used in a team while keeping file names specific to the actual key file
     * generated by GCP.
     * 
     * @param dataProjectName
     * @return An authenticated BigQuery instance
     * @throws FileNotFoundException
     * @throws IOException
     */
    public static BigQuery getBigQuery(String dataProjectName)
    throws FileNotFoundException, IOException
      {
        return getBigQuery(_DEFAULT_ENV_VAR_NAME, dataProjectName);
      }

    /**
     * Given the environment variable name provided, looks up the value which points to a path, and then
     * based on the project name, lookup the file "<GCP_SERVICE_ACCOUNT_CREDENTIALS_PATH>/<dataProjectName>.xxx.key.bq.json".
     * 'xxx' can be anything (and is optional) but is generally the first few characters of the original key file. This is done
     * so different keys to the same project could be used in a team while keeping file names specific to the actual key file
     * generated by GCP.
     * 
     * @param envVariable
     * @param dataProjectName
     * @return An authenticated BigQuery instance
     * @throws FileNotFoundException
     * @throws IOException
     */
    private static BigQuery getBigQuery(String envVariable, String dataProjectName)
    throws FileNotFoundException, IOException
      {
        String path = System.getenv(envVariable);
        if (TextUtil.isNullOrEmpty(path) == true)
          throw new FileNotFoundException("Cannot find the environment variable '" + envVariable + "' for the GCP credentials key file.");

        ServiceAccountCredentials credentials;
        // We are looking for the bq key file, ad only one file
        File P = new File(path);
        File K = null;
        int i = 0;
        for (File F : P.listFiles())
          if (F.isFile() == true && F.getName().startsWith(dataProjectName + ".") == true && F.getName().endsWith(".key.bq.json") == true)
            {
              ++i;
              K = F;
            }
        if (i == 0)
          {
            LOG.error("GCP BigQuery key file '" + dataProjectName + ".*.key.bq.json' not found in '" + path + "'.");
            throw new IOException("GCP BigQuery key file not found.");
          }
        else if (i > 1)
          throw new IOException("There are more than 1 file matching the pattern '" + dataProjectName + ".*.bq.key.json' in '" + path + "' for account key files: only 1 was expected.");

        try (FileInputStream serviceAccountStream = new FileInputStream(K))
          {
            credentials = ServiceAccountCredentials.fromStream(serviceAccountStream);
          }
        return BigQueryOptions.newBuilder().setCredentials(credentials).setProjectId(dataProjectName).build().getService();
      }

    /**
     * 
     * @param bq
     * @param datasetName
     * @return
     */
    public static boolean createDataset(BigQuery bq, String datasetName)
      {
        try
          {
            DatasetInfo datasetInfo = DatasetInfo.newBuilder(datasetName).build();
            if (bq.create(datasetInfo) != null)
              return true;
          }
        catch (BigQueryException e)
          {
          }
        return false;
      }

    /**
     * 
     * @param bq
     * @return
     * @throws Exception
     */
    public static List<Dataset> lookupDatasets(BigQuery bq)
    throws Exception
      {
        Page<Dataset> L = bq.listDatasets(DatasetListOption.all().pageSize(250));
        if (L == null)
          return new ArrayList<Dataset>();
        return (List<Dataset>) CollectionUtil.toList(L.iterateAll().iterator());
      }

    /**
     * 
     * @param bq
     * @param datasetName
     * @return
     * @throws Exception
     */
    public static List<Table> lookupTables(BigQuery bq, String datasetName)
    throws Exception
      {
        Page<Table> L = bq.listTables(datasetName, TableListOption.pageSize(250));
        if (L == null)
          return new ArrayList<Table>();
        return (List<Table>) CollectionUtil.toList(L.iterateAll().iterator());
      }

    /**
     * 
     * @param bq
     * @param datasetName
     * @param tableName
     * @return
     * @throws Exception
     */
    public static Table getTable(BigQuery bq, String datasetName, String tableName)
    throws Exception
      {
        return bq.getTable(datasetName, tableName);
      }

    /**
     * 
     * @param job
     * @return
     * @throws InterruptedException
     */
    public static Job completeJob(Job job)
      {
        List<BigQueryError> errs = null;
        try
          {
            LOG.info("Waiting for the BQ job to complete...");
            Job completedJob = job.waitFor();
            if (completedJob == null)
              {
                LOG.error("BigQuery job was not executed, or no longer exists.\n" + job.getStatus().getError());
                return null;
              }
            job = completedJob;
            errs = completedJob.getStatus().getExecutionErrors();
          }
        catch (BigQueryException E)
          {
            errs = new ArrayList<BigQueryError>();
            try {
              errs = E.getErrors();
            }
            catch (Exception X)
              {
                errs.add(E.getError());
              }
          }
        catch (InterruptedException E)
          {
            LOG.error("Error waiting for the job\n", E);
            return null;
          }
        if (errs != null && errs.isEmpty() == false)
          {
            StringBuilder str = new StringBuilder();
            int errorCount = 0;
            for (BigQueryError err : errs)
              {
                // LDH-NOTE: MAJOR HACK HERE!!!!!! We are getting back warning messages in the error list, and so we
                // think the job failed when it actually succeeded (we checked on the BQ side). So for now
                // we exclude explicit messages. Clearly a horrible thing to be doing!
                if (err.getMessage().indexOf("The input data has NULL values in one or more columns") == -1)
                  {
                    ++errorCount;
                  }
                str.append(" - " + err.getMessage() + " - " + err.getReason() + "\n");
              }
            LOG.error("BigQuery job was unable to load data to the table due to an error: \n" + str.toString());
            if (errorCount > 0)
              return null;
          }
        String stats = null;
        try // Bad Google... job.getStatistics can throw on nullptr on their own internal API calls.
          {
            stats = job.getStatistics().toString();
          }
        catch (Exception E)
          {
            LOG.warn("job.getStatistics() threw:\n", E);
            stats = E.getMessage();
          }
        LOG.info("BigQuery job completed successfully.\n" + stats + "\n");
        return job;
      }


    /**
     * Returns a job if it's done, null otherwise.
     * 
     * @param bq
     * @param jobId
     * @return
     * @throws Exception
     * @throws InterruptedException
     */
    public static Job checkJobDone(BigQuery bq, String jobId)
    throws Exception
      {
        Job job = bq.getJob(jobId);
        if (job == null)
          throw new Exception("Job cannot be found");
        return job.isDone() == true ? job : null;
      }

    public static class JobResults
      {
        protected JobResults(Job j, TableResult r)
          {
            _j = j;
            _r = r;
          }

        public final Job         _j;
        public final TableResult _r;
      }

    public static JobResults runQuery(BigQuery bq, String q)
      {
        try
          {
            LOG.debug(q);
            QueryJobConfiguration queryConfig = QueryJobConfiguration.newBuilder(q).setUseLegacySql(false).build();
            JobId jobId = JobId.newBuilder().build();
            JobInfo jobInfo = JobInfo.newBuilder(queryConfig).setJobId(jobId).build();
            Job job = bq.create(jobInfo);
            if (BQHelper.completeJob(job) != null)
              {
                TableResult results = job.getQueryResults();
                if (results != null)
                  return new JobResults(job, results);
              }
          }
        catch (Exception E)
          {
            LOG.error("Cannot execute BigQuery query:\n", E);
          }
        return null;
      }

    public static class JobCostDetails
      {
        protected JobCostDetails(long bytes, double cost, double costModeling)
          {
            _bytes = bytes;
            _cost = cost;
            _costModeling = costModeling;
          }

        public final long   _bytes;
        public final double _cost;
        public final double _costModeling;
      }

    /**
     * Returns the billed bytes and cost in cents for a given job, or null if the job could be
     * located or an exception occurred internally (see logs).
     * 
     * @param bq
     * @param jobId
     * @return LongDoublePair
     */
    public static JobCostDetails getJobCostInBytesCents(BigQuery bq, String jobId)
      {
        String q = "SELECT total_bytes_billed, cost_cents, cost_cents_modeling from TILDA.BQJobDetails where job_id=" + TextUtil.escapeSingleQuoteForSQL(jobId) + ";";
        JobResults jr = runQuery(bq, q);
        if (jr != null)
          for (FieldValueList row : jr._r.iterateAll())
            {
              long bytes = row.get("total_bytes_billed").getLongValue();
              double cost = row.get("cost_cents").getDoubleValue();
              double costModeling = row.get("cost_cents_modeling").getDoubleValue();
              return new JobCostDetails(bytes, cost, costModeling);
            }
        return null;
      }

    /**
     * Sets up a Writer to a BQ Table in the appropriate format. Once obtained, you can write date to the writer, and when done,
     * you can get the Job and check for completion with <code>boolean success = BQHelper.completeJob(writer.getJob());</code>
     *
     * @param bq
     * @param datasetName
     * @param tableName
     * @param format either 'csv' or 'jsonl' only
     * @return
     * @throws Exception
     */
    public static TableDataWriteChannel getTableWriterChannel(BigQuery bq, String datasetName, String tableName, String format, Schema schema, boolean truncate)
    throws Exception
      {
        TableId tableId = TableId.of(datasetName, tableName);
        FormatOptions FO = format.equalsIgnoreCase("csv") ? FormatOptions.csv()
        : format.equalsIgnoreCase("jsonl") ? FormatOptions.json()
        : null;
        if (FO == null)
          throw new Exception("Format '" + format + "' is neither 'csv' nor 'jsonl'.");

        WriteChannelConfiguration writeChannelConfiguration = WriteChannelConfiguration.newBuilder(tableId)
        .setFormatOptions(FO).setSchema(schema)
        .setWriteDisposition(truncate == true ? WriteDisposition.WRITE_TRUNCATE : WriteDisposition.WRITE_APPEND)
        .build();
        JobId jobId = JobId.newBuilder().build();
        TableDataWriteChannel channel = bq.writer(jobId, writeChannelConfiguration);
        channel.setChunkSize(4 * 1024 * 1024); // 4MB
        // == 139708 records in 3mn 4s 672ms (45,391.14 records/min)

        return channel;
      }

    public static Schema getTildaBQSchema(String SchemaName, String TableViewName)
    throws Exception
      {
        TildaObjectMetaData Obj = TildaMasterRuntimeMetaData.getTableObject(SchemaName, TableViewName);
        if (Obj == null)
          throw new Exception("Cannot locate Object/View '" + SchemaName + "." + TableViewName + "'.");

        // StringBuilder str = new StringBuilder();
        List<Field> fieldsList = new ArrayList<Field>();
        for (ColumnDefinition col : Obj.getColumnDefinitions())
          {
            Field F = Field.newBuilder(col.getName(), StandardSQLTypeName.valueOf(col.getType().getBigQueryType()))
            .setMode(col.isCollection() == true ? Field.Mode.REPEATED : col.isNullable() == false ? Field.Mode.REQUIRED : Field.Mode.NULLABLE)
            .setDescription(col.getDescription())
            .build();
            fieldsList.add(F);
            // if (str.length()!=0)
            // str.append(", ");
            // str.append(col.getName());
          }
        // LOG.debug("Schema for "+SchemaName+"."+TableViewName+": "+str.toString());

        return Schema.of(fieldsList);
      }

  }
